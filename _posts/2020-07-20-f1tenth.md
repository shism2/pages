---
toc: false
layout: post
title: We won the 7th F1/TENTH Autonomous Grand Prix
tags: [F1/TENTH, Autonomous racing]
image: "images/thumb_sized/car.jpg"

---

Our team won first place in the [7th F1/TENTH Autonomous Grand Prix at the World Congress of the International Federation of Automatic Control (IFAC 2020)](https://ifac2020.f1tenth.org/).

![award]({{ site.baseurl }}/images/f1tenth/official.png "Winning certificate")

## The F1/TENTH Grand Prix

[F1/TENTH](https://f1tenth.org/) is a project about designing, building, and racing with autonomous cars at the scale of 1:10 of formula-1 cars (thus the name F1/TENTH). Initially founded by researchers from the University of Pennsylvania, F1/TENTH has attracted an international community and is regularly holding racing competitions.   
The latest of these competitions, the 7th F1/TENTH Autonomous Grand Prix, was indented to be held physically in Berlin. However, due to Covid-19, the race was carried out virtually in a simulation environment. 
I and students from TU Wien participated in this Grand Prix under the team name *"TUfast TUfurious"*. Out of a total of 13 submitted teams, including teams from, South Korea, U.S., and Italy, our team won the competition.

## Our approach

Our agent implements a path following algorithm based on the race map, which the organizers released a week before the competition. We tested our agent with several pre-computed paths, including a very smooth one and one that drives the curves very aggressively. Eventually, we settled for a path, as shown below (right), that comprises of long straight parts where the agent can accelerate.

![award]({{ site.baseurl }}/images/f1tenth/comb.png "Left: Smooth baseline trajectory, Right: Proposed faster path")

After we fixed our path following core, we developed a velocity controller module. Based on the car's current position, our velocity controller looks ahead of the planned path and estimates how much steering the agent has to do in the next couple of seconds. If the agent is expected to steer a lot, the velocity controller will reduce the car's speed. Vice versa, if the track ahead is a straight part, the velocity controller will accelerate the vehicle. How far the velocity module looks ahead and how much to brake and accelerate in which conditions, is optimized using reinforcement learning.
As for the learning part, we opt for a good-old random search algorithm.
On top of the path following algorithm and the velocity controller, we implemented two methods that gave us an edge during the race.
Our first improvement is a manual starting maneuver. Essentially, at the beginning of the race, we overwrite the velocity controller by accelerating with the maximum throttle. After a few seconds, we assign the control back to the learned velocity module.
Our second improvement is a collision avoidance procedure. Our assumption the collision avoidance was that the opponents behave either near-optimal. Thus a safe overtaking during the race is not possible. Consequently, if our agent foresees colliding into the other car, for instance, because the other car slows down before a corner, our collision avoidance procedure slows down our car as well.

After we implemented all parts of our agent, we rigorously tested it.
For instance, in the animation, we compared our agent to an opponent who performs a near-optimal start but then slows down halfway through the track.

![award]({{ site.baseurl }}/images/f1tenth/testing.gif "Our agent (blue) vs a tested opponent that starts near-optimal but later slows down")

Our agent correctly foresees a crash a the beginning and slows down. After letting the opponent pass, our agent catches up quickly with the other car, when our agent has to slow down again to avoid a crash. 

## The competition
During the head-to-head races, our agent demonstrated that it performs remarkably well in a variety of scenarios.

![award]({{ site.baseurl }}/images/f1tenth/f110.png "Tournament bracket")

For instance, in the first race, our agent quickly overtook the opponent independently of starting in the advantaged or disadvantaged starting position.
In the second race, our agent correctly avoided a crash with the fast-starting opponent. Nonetheless, our agent won due to a faster lap time.
In the final race, our agent won because the other team's car crashed into our agent, demonstrating how vital a well-tested collision avoidance is.
All-in-all our agent was able to win because it performed excellently in a diverse set of conditions.

## Acknowledgement

I want to thank all of my team members, Thomas Pintaric, Bernhard Schögl, Axel Brunnbauer, Hannes Brantner, and Andreas Brandstätter, for contributing to our submission and making the first-place possible. I also want to thank Radu Grosu for organizing the autonomous racing car course at TU Wien.

![award]({{ site.baseurl }}/images/f1tenth/celebrate3.jpg "Prof. Radu Grosu celebrating")