---
toc: false
# sticky_rank: 2
layout: post
title: Neural Circuit Policies (Part 1) - An Introduction
tags: [NCP]
image: "images/thumb_sized/worm.png"
---

This blog series will briefly explore all the concepts and challenges involved in our [Neural Circuit Policies (NCP)]((https://rdcu.be/b8sEo)) machine learning model. 
Particularly, we will discuss topics like brain-inspired machine learning models, neural networks defined by differential equations, recurrent neural networks, and sparsity.

The full tabel of conent is

- **Part 1: Introduction**
- [Part 2: An old neuron model revisted]({{ site.baseurl }}/2020/09/15/the_model.html)
- [Part 3: An unusual ODE-solver]({{ site.baseurl }}/2020/09/16/ode_solver.html)
- [Part 4: Training RNN is difficult]({{ site.baseurl }}/2021/02/18/rnn.html)
- [Part 5: Sparsity in machine learning]({{ site.baseurl }}/2021/03/08/sparsity.html)
- [Part 6: Pros and Cons of Neural Circuit Policies]({{ site.baseurl }}/2021/06/29/procon.html)

## Biological vs artificial neural networks

The term *neural* implies the origin of neural networks lies in biological nervous systems. Indeed, artificial neural networks' original purpose was to build intelligent algorithms inspired by how information processing happens in human and animal brains. 
However, modern neural networks for building powerful machine learning models look quite distinct compared to their biological counterparts.
There are two critical differences between artificial and biological neural networks: the computational model and the architecture.

![award]({{ site.baseurl }}/images/wormnet/t.png "Left: Resnet architecture (He et al. 2016), Right: Subset of the C. elegans connectome (Copyright Emmons Lab/wormwiring.org)")

Biological neurons are cells whose cell-wall have an electrical charge depending on the concentration of certain ions inside vs. outside the cell. 
The number of ions inside the cell can be changed by mechanisms of the cell itself when the cell's electrical charge exceeds a threshold or via neurotransmitters released by synapses coming from other neurons. 
On the other side of the spectrum, an artificial neuron is simply a weighted summation of its inputs, followed by a non-linear function. This high-level abstraction is an extreme simplification of the underlying information processing mechanism. 

![award]({{ site.baseurl }}/images/wormnet/hierarchy.png "Abstraction hierarchy of various neuron models")

On the one hand, this simplification lets us easily design deep neural networks of millions of units with only a few code lines.
One the other hand, it raises the question of whether we lose some important properties and aspects of biological neurons.

The second major difference between artificial and biological neural networks is their wiring architectures.
Biological neural networks appear chaotic at first glance and require extensive research to understand and characterize their wiring principles. 
Artificial neural networks have a well-defined layer-by-layer structure, which is often guided by computational reasons. For instance, cache efficient dense matrix multiplication algorithms make the use of fully-connected layers very convenient. Consequently, writing a fully-connected layer in Pytorch or TensorFlow requires fewer code lines than creating a sparsely connected layer.

Given the two discrepancies between artificial and biological neural networks mentioned above, we ask the following question in our research:

> What do we gain something, and what costs do we have to pay if we design more biologically inspired machine learning models?

But there are already a million papers out there asking similar questions, what's so special about your research?

That's correct. But different from other research out there, we don't look at human brains for our inspirations.
We don't even look at rats or mice brains for our comparisons.
Heck, we don't even consider the brains of insects or fish for our study.
We look at the arguably simplest animal with a functioning nervous system out there: The *Caenorhabditis elegans* worm.

![award]({{ site.baseurl }}/images/wormnet/c_elegans.jpg "C. elegans adult (CC BY-SA 3.0)")

From a modeling viewpoint, the *C. elegans* organism has two key advantages:

- C. elegans' nervous system consists of only 302 neurons and around 9000 synapses, and its wiring is well-studied [^1]. 
- The neurons of *C. elegans'* nervous system don't express any spiking patterns, which makes modeling them much simpler.

In our research on the [Neural Circuit Policies (NCP)]((https://rdcu.be/b8sEo)), we try to build machine learning models motivated by the *C. elegans* nervous system. 
By doing so, we have to pay a cost, as we constrain ourselves to such models in contrast to standard artificial neural networks, whose modeling space is purely constraint by memory and compute limitations.
However, there are potentially some advantages and benefits we gain.
Our objective is to better understand what's necessary for effective neural information processing to emerge. 

## What to expect

In this blog series, we take a journey through some of the methods and challenges faced when we developed the [NCPs](https://rdcu.be/b8sEo). 
Essentially, we talk about the process of mapping the abstract idea of brain-inspired machine learning into our concrete NCP implementation:

![award]({{ site.baseurl }}/images/wormnet/ode_to_rnn.png "Modelling process in a nutshell")

- **Part 1: Introduction**
- [Part 2: An old neuron model revisted]({{ site.baseurl }}/2020/09/15/the_model.html)
- [Part 3: An unusual ODE-solver]({{ site.baseurl }}/2020/09/16/ode_solver.html)
- [Part 4: Training RNN is difficult]({{ site.baseurl }}/2021/02/18/rnn.html)
- [Part 5: Sparsity in machine learning]({{ site.baseurl }}/2021/03/08/sparsity.html)
- [Part 6: Pros and Cons of Neural Circuit Policies]({{ site.baseurl }}/2021/06/29/procon.html)

## References

[^1]: [wormatlas.org](https://www.wormatlas.org/)
