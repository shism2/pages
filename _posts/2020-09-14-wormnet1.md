---
toc: false
sticky_rank: 2
layout: post
title: The wormnet project
tags: [NCP, wormnet]
image: "images/wormnet/worm.png"
---

This is the first part in a series explaining our recent paper titled XXX.

- Part 1: [An old neuron model revisted]({{ site.baseurl }}/2020/09/15/the_model.html)
- Part 2: [An unusual ODE-solver]({{ site.baseurl }}/2020/09/16/ode_solver.html)

## Biological vs artificial neural networks

The term *neural* implies the origin of neural networks lies in biological nervous systems. Indeed, artificial neural networks' original purpose was to build intelligent algorithms inspired by how information processing happens in human and animal brains. 
However, modern neural networks for building powerful machine learning models look quite distinct compared to their biological counterparts.
There are two critical differences between artificial and biological neural networks: the computational model and the architecture.

![award]({{ site.baseurl }}/images/wormnet/t.png "Left: Resnet architecture (He et al. 2016), Right: Subset of the C. elegans connectome (Copyright Emmons Lab/wormwiring.org)")

Biological neurons are cells whose cell-wall have an electrical charge depending on the concentration of certain ions inside vs. outside the cell. 
The number of ions inside the cell can be changed by mechanisms of the cell itself when the cell's electrical charge exceeds a threshold or via neurotransmitters released by synapses coming from other neurons. 
On the other side of the spectrum, an artificial neuron is simply a weighted summation of its inputs, followed by a non-linear function. This high-level abstraction is an extreme simplification of the underlying information processing mechanism. 
On the one hand, this simplification lets us easily design deep neural networks of millions of units with only a few code lines.
One the other hand, it raises the question of whether we lose some important properties and aspects of biological neurons.

The second major difference between artificial and biological neural networks is their wiring architectures.
Biological neural networks appear chaotic at first glance and require extensive research to understand and characterize their wiring principles. 
Artificial neural networks have a well-defined layer-by-layer structure, which is often guided by computational reasons. For instance, cache efficient dense matrix multiplication algorithms make the use of fully-connected layers very convenient. Consequently, writing a fully-connected layer in Pytorch or TensorFlow requires fewer code lines than creating a sparsely connected layer.

Given the two discrepancies between artificial and biological neural networks mentioned above, we ask the following question in our research:

> What do we gain something, and what costs do we have to pay if we design more biologically inspired machine learning models?

But there are already a million papers out there asking similar questions, what's so special about your research?

That's correct. But different from other research out there, we don't look at human brains for our inspirations.
We don't even look at rats or mice brains for our comparisons.
Heck, we don't even consider the brains of insects or fish for our study.
We look at the arguably simplest animal with a functioning nervous system out there: The *Caenorhabditis elegans* worm.

![award]({{ site.baseurl }}/images/wormnet/c_elegans.jpg "*C. elegans* adult (CC BY-SA 3.0)")

From a modeling viewpoint, the *C. elegans* organism has two key advantages:

- C. elegans' nervous system consists of only 302 neurons and around 9000 synapses, and its wiring is well-studied [^1]. 
- The neurons of *C. elegans'* nervous system don't express any spiking patterns, which makes modeling them much simpler.

In our research, i.e., the wormnet project, we try to build machine learning models motivated by the *C. elegans* nervous system. 
By doing so, we have to pay a cost, as we constrain ourselves to such models in contrast to standard artificial neural networks, whose modeling space is purely constraint by memory and compute limitations.
However, there are potentially some advantages and benefits we gain.
Our objective is to better understand what's necessary for effective neural information processing to emerge. 

## What to expect

In this blog series, we take a quick journey through four years of research, which started in 2016, up to our recent paper XXX. 
Essentially, we talk about the requirements and difficulties of each step of the following process:

![award]({{ site.baseurl }}/images/wormnet/ode_to_rnn.png "Modelling process in a nutshell")

After that, we will discuss our observed advantages and downsides of using such a unique machine learning model.


## References

[^1]: [wormatlas.org](https://www.wormatlas.org/)
