{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moore's Law - Machine Learning Research Edition\n",
    "> A post about how Moore's law is driving machine learning research\n",
    "\n",
    "- toc: false \n",
    "- badges: false\n",
    "- comments: false\n",
    "- categories: [jupyter]\n",
    "- image: images/gpu.jpg\n",
    "- author: Mathias Lechner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenAI recently released a [blog post](https://openai.com/blog/ai-and-efficiency/), showing that the advances in algorithmic efficiency for training neural nets outpaced the scaling of Moore's law. \n",
    "In particular, the amount of transistors in silicon chips [doubles every two years](https://newsroom.intel.com/wp-content/uploads/sites/11/2018/05/moores-law-electronics.pdf), whereas the efficiency of training a neural net to a certain accuracy level doubles every 16 to 17 months. \n",
    "While this progress is impressive, I am arguing that Moore's law is one of the main drivers of machine learning research. Thus, the advances in neural nets training efficiency are built on the shoulders of Moore's law.\n",
    "In essence, I am stating the following law:\n",
    "\n",
    "> The amount of hyperparameter & architecture tuning that can be done for a fixed budget **doubles** every two years\n",
    "> \n",
    "> *Moore's Law - Machine Learning Research Edition*\n",
    "\n",
    "\n",
    "By *budget* I mean time, money and compute resources.\n",
    "\n",
    "## Machine Learning Research\n",
    "If we look at the methodology of machine learning research, we notice an iterative paradigm composed of the following steps.\n",
    "\n",
    "1. We have an idea\n",
    "2. We test the idea\n",
    "3. Based on the results, we refine and improve the idea.\n",
    "\n",
    "Once this iterative process yields noteworthy results, the idea and corresponding test results get distilled into a research paper.\n",
    "\n",
    "Let's say we want to speed up our research. \n",
    "Common sense tells us that we can speed up any process by getting rid of its bottlenecks.\n",
    "The most dominant bottleneck in the procedure above is obviously step number 2. \n",
    "\n",
    "We could run more machine learning experiments if we simply buy a larger quantity of faster compute units.\n",
    "But what if our budget is limited? How can we speed up our research then?\n",
    "\n",
    "The answer is simply waiting.\n",
    "Yes! Moore's law tells us that every 2 years, we get roughly twice the compute performance for the same budget.\n",
    "For instance, here is a plot of how the 32-bit floating-point of Nvidia GPU performance increased in the past decade:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GPU</th>\n",
       "      <th>Year</th>\n",
       "      <th>Gen</th>\n",
       "      <th>Memory</th>\n",
       "      <th>Compute</th>\n",
       "      <th>Tensor cores</th>\n",
       "      <th>Node</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GTX 580</td>\n",
       "      <td>2010-11-01</td>\n",
       "      <td>Fermi</td>\n",
       "      <td>1.5GB</td>\n",
       "      <td>1.581</td>\n",
       "      <td>False</td>\n",
       "      <td>40nm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GTX 680</td>\n",
       "      <td>2012-02-01</td>\n",
       "      <td>Kepler</td>\n",
       "      <td>2GB</td>\n",
       "      <td>3.250</td>\n",
       "      <td>False</td>\n",
       "      <td>28nm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>K40</td>\n",
       "      <td>2013-10-01</td>\n",
       "      <td>Kepler</td>\n",
       "      <td>12GB</td>\n",
       "      <td>5.046</td>\n",
       "      <td>False</td>\n",
       "      <td>28nm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Titan Black</td>\n",
       "      <td>2014-02-01</td>\n",
       "      <td>Kepler</td>\n",
       "      <td>6GB</td>\n",
       "      <td>5.645</td>\n",
       "      <td>False</td>\n",
       "      <td>28nm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K80</td>\n",
       "      <td>2014-11-01</td>\n",
       "      <td>Kepler</td>\n",
       "      <td>2x12GB</td>\n",
       "      <td>8.226</td>\n",
       "      <td>False</td>\n",
       "      <td>28nm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GTX 980 Ti</td>\n",
       "      <td>2015-06-01</td>\n",
       "      <td>Maxwell</td>\n",
       "      <td>6GB</td>\n",
       "      <td>6.060</td>\n",
       "      <td>False</td>\n",
       "      <td>28nm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>M40</td>\n",
       "      <td>2015-11-01</td>\n",
       "      <td>Maxwell</td>\n",
       "      <td>12GB</td>\n",
       "      <td>6.844</td>\n",
       "      <td>False</td>\n",
       "      <td>28nm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GTX 1080</td>\n",
       "      <td>2016-05-01</td>\n",
       "      <td>Pascal</td>\n",
       "      <td>8GB</td>\n",
       "      <td>8.873</td>\n",
       "      <td>False</td>\n",
       "      <td>16nm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>P100</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>Pascal</td>\n",
       "      <td>16GB</td>\n",
       "      <td>10.610</td>\n",
       "      <td>False</td>\n",
       "      <td>16nm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GTX 1080Ti</td>\n",
       "      <td>2017-03-01</td>\n",
       "      <td>Pascal</td>\n",
       "      <td>11GB</td>\n",
       "      <td>11.340</td>\n",
       "      <td>False</td>\n",
       "      <td>16nm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Titan V</td>\n",
       "      <td>2017-12-01</td>\n",
       "      <td>Volta</td>\n",
       "      <td>12GB</td>\n",
       "      <td>14.900</td>\n",
       "      <td>True</td>\n",
       "      <td>12nm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>V100</td>\n",
       "      <td>2018-03-01</td>\n",
       "      <td>Volta</td>\n",
       "      <td>16/32GB</td>\n",
       "      <td>14.130</td>\n",
       "      <td>True</td>\n",
       "      <td>12nm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>T4</td>\n",
       "      <td>2018-09-13</td>\n",
       "      <td>Turing</td>\n",
       "      <td>16GB</td>\n",
       "      <td>8.141</td>\n",
       "      <td>True</td>\n",
       "      <td>12nm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>RTX 2080 Ti</td>\n",
       "      <td>2018-11-01</td>\n",
       "      <td>Turing</td>\n",
       "      <td>12GB</td>\n",
       "      <td>13.450</td>\n",
       "      <td>True</td>\n",
       "      <td>12nm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Titan RTX</td>\n",
       "      <td>2018-12-01</td>\n",
       "      <td>Turing</td>\n",
       "      <td>24GB</td>\n",
       "      <td>16.310</td>\n",
       "      <td>True</td>\n",
       "      <td>12nm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>A100</td>\n",
       "      <td>2020-05-01</td>\n",
       "      <td>Ampere</td>\n",
       "      <td>40GB</td>\n",
       "      <td>19.490</td>\n",
       "      <td>True</td>\n",
       "      <td>7nm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            GPU       Year      Gen   Memory  Compute  Tensor cores  Node\n",
       "0       GTX 580 2010-11-01    Fermi    1.5GB    1.581         False  40nm\n",
       "1       GTX 680 2012-02-01   Kepler      2GB    3.250         False  28nm\n",
       "2           K40 2013-10-01   Kepler     12GB    5.046         False  28nm\n",
       "3   Titan Black 2014-02-01   Kepler      6GB    5.645         False  28nm\n",
       "4           K80 2014-11-01   Kepler   2x12GB    8.226         False  28nm\n",
       "5    GTX 980 Ti 2015-06-01  Maxwell      6GB    6.060         False  28nm\n",
       "6           M40 2015-11-01  Maxwell     12GB    6.844         False  28nm\n",
       "7      GTX 1080 2016-05-01   Pascal      8GB    8.873         False  16nm\n",
       "8          P100 2016-04-01   Pascal     16GB   10.610         False  16nm\n",
       "9    GTX 1080Ti 2017-03-01   Pascal     11GB   11.340         False  16nm\n",
       "10      Titan V 2017-12-01    Volta     12GB   14.900          True  12nm\n",
       "11         V100 2018-03-01    Volta  16/32GB   14.130          True  12nm\n",
       "12           T4 2018-09-13   Turing     16GB    8.141          True  12nm\n",
       "13  RTX 2080 Ti 2018-11-01   Turing     12GB   13.450          True  12nm\n",
       "14    Titan RTX 2018-12-01   Turing     24GB   16.310          True  12nm\n",
       "15         A100 2020-05-01   Ampere     40GB   19.490          True   7nm"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "df = pd.DataFrame({'GPU': ['GTX 580'],\n",
    "                   'Year':  [pd.Timestamp(2010,11,1)],\n",
    "        'Gen': ['Fermi'],\n",
    "        'Memory': ['1.5GB'],\n",
    "        'Compute': [1.581],\n",
    "        'Tensor cores': [False],\n",
    "        'Node': ['40nm']\n",
    "        })\n",
    "df = df.append({'Year': pd.Timestamp(2012,2,1), \n",
    "        'GPU': 'GTX 680',\n",
    "        'Gen': 'Kepler',\n",
    "        'Compute': 3.250,\n",
    "        'Memory': '2GB', \n",
    "        'Tensor cores': False,\n",
    "        'Node': '28nm',\n",
    "        },ignore_index=True)\n",
    "df = df.append({'Year': pd.Timestamp(2013,10,1), \n",
    "        'GPU': 'K40',\n",
    "        'Gen': 'Kepler',\n",
    "        'Compute': 5.046,\n",
    "        'Tensor cores': False,\n",
    "        'Memory': '12GB',\n",
    "        'Node': '28nm',\n",
    "        },ignore_index=True)\n",
    "df = df.append({'Year': pd.Timestamp(2014,2,1), \n",
    "        'GPU': 'Titan Black',\n",
    "        'Gen': 'Kepler',\n",
    "        'Tensor cores': False,\n",
    "        'Memory': '6GB',\n",
    "        'Compute': 5.645,\n",
    "        'Node': '28nm',\n",
    "        },ignore_index=True)\n",
    "df = df.append({'Year': pd.Timestamp(2014,11,1), \n",
    "        'GPU': 'K80',\n",
    "        'Gen': 'Kepler',\n",
    "        'Compute': 8.226,\n",
    "        'Tensor cores': False,\n",
    "        'Memory': '2x12GB',\n",
    "        'Node': '28nm',\n",
    "        },ignore_index=True)\n",
    "df = df.append({'Year': pd.Timestamp(2015,6,1), \n",
    "        'GPU': 'GTX 980 Ti',\n",
    "        'Gen': 'Maxwell',\n",
    "        'Compute':6.060 ,\n",
    "        'Tensor cores': False,\n",
    "        'Memory': '6GB',\n",
    "        'Node': '28nm',\n",
    "        },ignore_index=True)\n",
    "\n",
    "\n",
    "df = df.append({'Year': pd.Timestamp(2015,11,1), \n",
    "        'GPU': 'M40',\n",
    "        'Gen': 'Maxwell',\n",
    "        'Compute': 6.844,\n",
    "        'Tensor cores': False,\n",
    "        'Memory': '12GB',\n",
    "        'Node': '28nm',\n",
    "        },ignore_index=True)\n",
    "\n",
    "df = df.append({'Year': pd.Timestamp(2016,5,1), \n",
    "        'GPU': 'GTX 1080',\n",
    "        'Gen': 'Pascal',\n",
    "        'Compute': 8.873,\n",
    "        'Memory': '8GB',\n",
    "        'Tensor cores': False,\n",
    "        'Node': '16nm',\n",
    "        },ignore_index=True)\n",
    "\n",
    "\n",
    "df = df.append({'Year': pd.Timestamp(2016,4,1), \n",
    "        'GPU': 'P100',\n",
    "        'Gen': 'Pascal',\n",
    "        'Compute': 10.61,\n",
    "        'Memory': '16GB',\n",
    "        'Tensor cores': False,\n",
    "        'Node': '16nm',\n",
    "        },ignore_index=True)\n",
    "\n",
    "df = df.append({'Year': pd.Timestamp(2017,3,1), \n",
    "        'GPU': 'GTX 1080Ti',\n",
    "        'Gen': 'Pascal',\n",
    "        'Compute': 11.34,\n",
    "        'Memory': '11GB',\n",
    "        'Tensor cores': False,\n",
    "        'Node': '16nm',\n",
    "        },ignore_index=True)\n",
    "\n",
    "df = df.append({'Year': pd.Timestamp(2017,12,1), \n",
    "        'GPU': 'Titan V',\n",
    "        'Gen': 'Volta',\n",
    "        'Compute': 14.90,\n",
    "        'Memory': '12GB',\n",
    "        'Tensor cores': True,\n",
    "        'Node': '12nm',\n",
    "        },ignore_index=True)\n",
    "df = df.append({'Year': pd.Timestamp(2018,3,1), \n",
    "        'GPU': 'V100',\n",
    "        'Gen': 'Volta',\n",
    "        'Compute': 14.13,\n",
    "        'Memory': '16/32GB',\n",
    "        'Tensor cores': True,\n",
    "        'Node': '12nm',\n",
    "        },ignore_index=True)\n",
    "df = df.append({'Year': pd.Timestamp(2018,9,13), \n",
    "        'GPU': 'T4',\n",
    "        'Gen': 'Turing',\n",
    "        'Compute': 8.141 ,\n",
    "        'Memory': '16GB',\n",
    "        'Tensor cores': True,\n",
    "        'Node': '12nm',\n",
    "        },ignore_index=True)\n",
    "df = df.append({'Year': pd.Timestamp(2018,11,1), \n",
    "        'GPU': 'RTX 2080 Ti',\n",
    "        'Gen': 'Turing',\n",
    "        'Compute': 13.45,\n",
    "        'Memory': '12GB',\n",
    "        'Tensor cores': True,\n",
    "        'Node': '12nm',\n",
    "        },ignore_index=True)\n",
    "df = df.append({'Year': pd.Timestamp(2018,12,1), \n",
    "        'GPU': 'Titan RTX',\n",
    "        'Gen': 'Turing',\n",
    "        'Compute': 16.31,\n",
    "        'Memory': '24GB',\n",
    "        'Tensor cores': True,\n",
    "        'Node': '12nm',\n",
    "        },ignore_index=True)\n",
    "\n",
    "df = df.append({'Year': pd.Timestamp(2020,5,1), \n",
    "        'GPU': 'A100',\n",
    "        'Gen': 'Ampere',\n",
    "        'Compute': 19.49 ,\n",
    "        'Memory': '40GB',\n",
    "        'Tensor cores': True,\n",
    "        'Node': '7nm',\n",
    "        },ignore_index=True)\n",
    "\n",
    " \n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-bff6319d7fc3476db42b13346ec17902\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-bff6319d7fc3476db42b13346ec17902\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-bff6319d7fc3476db42b13346ec17902\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.8.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function loadScript(lib) {\n",
       "      return new Promise(function(resolve, reject) {\n",
       "        var s = document.createElement('script');\n",
       "        s.src = paths[lib];\n",
       "        s.async = true;\n",
       "        s.onload = () => resolve(paths[lib]);\n",
       "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "      });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else if (typeof vegaEmbed === \"function\") {\n",
       "      displayChart(vegaEmbed);\n",
       "    } else {\n",
       "      loadScript(\"vega\")\n",
       "        .then(() => loadScript(\"vega-lite\"))\n",
       "        .then(() => loadScript(\"vega-embed\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"layer\": [{\"mark\": {\"type\": \"circle\", \"size\": 60}, \"encoding\": {\"color\": {\"type\": \"nominal\", \"field\": \"Gen\"}, \"tooltip\": [{\"type\": \"quantitative\", \"field\": \"Compute\"}, {\"type\": \"nominal\", \"field\": \"Node\"}, {\"type\": \"nominal\", \"field\": \"Gen\"}, {\"type\": \"nominal\", \"field\": \"Memory\"}, {\"type\": \"nominal\", \"field\": \"Tensor cores\"}], \"x\": {\"type\": \"temporal\", \"field\": \"Year\", \"scale\": {\"domain\": [\"2010-01-01T00:00:00\", \"2021-01-01T00:00:00\"]}}, \"y\": {\"type\": \"quantitative\", \"axis\": {\"title\": \"float32 Teraflop/s\"}, \"field\": \"Compute\"}}, \"height\": 400, \"width\": 600}, {\"mark\": {\"type\": \"text\", \"align\": \"left\", \"baseline\": \"middle\", \"dx\": 7}, \"encoding\": {\"color\": {\"type\": \"nominal\", \"field\": \"Gen\"}, \"text\": {\"type\": \"nominal\", \"field\": \"GPU\"}, \"tooltip\": [{\"type\": \"quantitative\", \"field\": \"Compute\"}, {\"type\": \"nominal\", \"field\": \"Node\"}, {\"type\": \"nominal\", \"field\": \"Gen\"}, {\"type\": \"nominal\", \"field\": \"Memory\"}, {\"type\": \"nominal\", \"field\": \"Tensor cores\"}], \"x\": {\"type\": \"temporal\", \"field\": \"Year\", \"scale\": {\"domain\": [\"2010-01-01T00:00:00\", \"2021-01-01T00:00:00\"]}}, \"y\": {\"type\": \"quantitative\", \"axis\": {\"title\": \"float32 Teraflop/s\"}, \"field\": \"Compute\"}}, \"height\": 400, \"width\": 600}], \"data\": {\"name\": \"data-3b7fa562e835dc8443afef5290c12238\"}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.8.1.json\", \"datasets\": {\"data-3b7fa562e835dc8443afef5290c12238\": [{\"GPU\": \"GTX 580\", \"Year\": \"2010-11-01T00:00:00\", \"Gen\": \"Fermi\", \"Memory\": \"1.5GB\", \"Compute\": 1.581, \"Tensor cores\": false, \"Node\": \"40nm\"}, {\"GPU\": \"GTX 680\", \"Year\": \"2012-02-01T00:00:00\", \"Gen\": \"Kepler\", \"Memory\": \"2GB\", \"Compute\": 3.25, \"Tensor cores\": false, \"Node\": \"28nm\"}, {\"GPU\": \"K40\", \"Year\": \"2013-10-01T00:00:00\", \"Gen\": \"Kepler\", \"Memory\": \"12GB\", \"Compute\": 5.046, \"Tensor cores\": false, \"Node\": \"28nm\"}, {\"GPU\": \"Titan Black\", \"Year\": \"2014-02-01T00:00:00\", \"Gen\": \"Kepler\", \"Memory\": \"6GB\", \"Compute\": 5.645, \"Tensor cores\": false, \"Node\": \"28nm\"}, {\"GPU\": \"K80\", \"Year\": \"2014-11-01T00:00:00\", \"Gen\": \"Kepler\", \"Memory\": \"2x12GB\", \"Compute\": 8.226, \"Tensor cores\": false, \"Node\": \"28nm\"}, {\"GPU\": \"GTX 980 Ti\", \"Year\": \"2015-06-01T00:00:00\", \"Gen\": \"Maxwell\", \"Memory\": \"6GB\", \"Compute\": 6.06, \"Tensor cores\": false, \"Node\": \"28nm\"}, {\"GPU\": \"M40\", \"Year\": \"2015-11-01T00:00:00\", \"Gen\": \"Maxwell\", \"Memory\": \"12GB\", \"Compute\": 6.844, \"Tensor cores\": false, \"Node\": \"28nm\"}, {\"GPU\": \"GTX 1080\", \"Year\": \"2016-05-01T00:00:00\", \"Gen\": \"Pascal\", \"Memory\": \"8GB\", \"Compute\": 8.873, \"Tensor cores\": false, \"Node\": \"16nm\"}, {\"GPU\": \"P100\", \"Year\": \"2016-04-01T00:00:00\", \"Gen\": \"Pascal\", \"Memory\": \"16GB\", \"Compute\": 10.61, \"Tensor cores\": false, \"Node\": \"16nm\"}, {\"GPU\": \"GTX 1080Ti\", \"Year\": \"2017-03-01T00:00:00\", \"Gen\": \"Pascal\", \"Memory\": \"11GB\", \"Compute\": 11.34, \"Tensor cores\": false, \"Node\": \"16nm\"}, {\"GPU\": \"Titan V\", \"Year\": \"2017-12-01T00:00:00\", \"Gen\": \"Volta\", \"Memory\": \"12GB\", \"Compute\": 14.9, \"Tensor cores\": true, \"Node\": \"12nm\"}, {\"GPU\": \"V100\", \"Year\": \"2018-03-01T00:00:00\", \"Gen\": \"Volta\", \"Memory\": \"16/32GB\", \"Compute\": 14.13, \"Tensor cores\": true, \"Node\": \"12nm\"}, {\"GPU\": \"RTX 2080 Ti\", \"Year\": \"2018-11-01T00:00:00\", \"Gen\": \"Turing\", \"Memory\": \"12GB\", \"Compute\": 13.45, \"Tensor cores\": true, \"Node\": \"12nm\"}, {\"GPU\": \"Titan RTX\", \"Year\": \"2018-12-01T00:00:00\", \"Gen\": \"Turing\", \"Memory\": \"24GB\", \"Compute\": 16.31, \"Tensor cores\": true, \"Node\": \"12nm\"}, {\"GPU\": \"A100\", \"Year\": \"2020-05-01T00:00:00\", \"Gen\": \"Ampere\", \"Memory\": \"40GB\", \"Compute\": 19.49, \"Tensor cores\": true, \"Node\": \"7nm\"}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide_input\n",
    "points = alt.Chart(df).mark_circle(size=60).encode(\n",
    "    alt.X('Year:T',scale=alt.Scale(domain=(pd.Timestamp(2010,1,1), pd.Timestamp(2021,1,1)))),\n",
    "    y=alt.Y('Compute',axis=alt.Axis(title=\"float32 Teraflop/s\")),\n",
    "    color='Gen',\n",
    "    tooltip=['Compute', 'Node','Gen','Memory','Tensor cores']\n",
    ").properties(\n",
    "    width=600,\n",
    "    height=400\n",
    ")\n",
    "\n",
    "text = points.mark_text(\n",
    "    align='left',\n",
    "    baseline='middle',\n",
    "    dx=7\n",
    ").encode(\n",
    "    text='GPU'\n",
    ")\n",
    "points + text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This chart does not even include the improvements of Mixed-precision methods and other tricks that achieve higher performance by sacrificing arithmetic precision. For instance, Nvidia's latest A100 can perform 156 Teraflop/s when using the slightly less precise [TensorFloat32](https://devblogs.nvidia.com/nvidia-ampere-architecture-in-depth/) format.\n",
    "If we compare the TensorFloat32 throughput of the A100 to the GTX 580 used by Alex Krizhevsky to train [AlexNet](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf), we see a 100x jump in compute performance in almost exactly ten years.\n",
    "\n",
    "\n",
    "## But what about larger models and datasets?\n",
    "\n",
    "Of course, the statement about the doubling of the hyperparameter & architecture tuning assumes that the datasets and extend of the networks does not change dramatically.\n",
    "However, given that ImageNet is still the de-facto standard computer vision benchmark (special credit to Prof. Fei-Fei), and the fact that the top-performing networks in 2020 ([EfficientNet](https://arxiv.org/pdf/1905.11946.pdf)) are smaller than their 2016 counterparts (ResNet/[ResNeXt](https://arxiv.org/pdf/1611.05431.pdf)), this assumptions holds."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
