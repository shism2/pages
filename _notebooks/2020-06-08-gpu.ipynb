{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Teraflops Era\n",
    "> A post about how Moore's law is driving progress in machine learning research\n",
    "\n",
    "- toc: false \n",
    "- badges: false\n",
    "- comments: false\n",
    "- categories: [jupyter]\n",
    "- image: images/thumb_sized/gpu.jpg\n",
    "- author: Mathias Lechner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenAI recently released a [blog post](https://openai.com/blog/ai-and-efficiency/), showing that the advances in algorithmic efficiency for training neural nets outpaced the scaling of Moore's law. \n",
    "In particular, the amount of transistors in silicon chips [doubles every two years](https://newsroom.intel.com/wp-content/uploads/sites/11/2018/05/moores-law-electronics.pdf), whereas the efficiency of training a neural net to a certain accuracy level currently doubles every 16 to 17 months. \n",
    "While this progress is impressive, I am arguing that Moore's law is one of the main drivers of machine learning research. Thus, the advances in neural nets training efficiency are built on the shoulders of Moore's law.\n",
    "In essence, I am stating the following law:\n",
    "\n",
    "> The amount of machine learning experiments that can be done for a fixed budget **doubles** every two years\n",
    "> \n",
    "> ***Moore's Law - Machine Learning Research Edition***\n",
    "\n",
    "\n",
    "By *budget* I am refering to time, money and compute resources. My definition of *machine learning experiments* involves any experiment to test new network designs, layers, loss functions, and training methods (e.g., self-supervised pre-training).\n",
    "\n",
    "\n",
    "## Machine Learning Research\n",
    "If we look at the methodology of machine learning research, we notice an iterative paradigm composed of the following steps.\n",
    "\n",
    "1. We have an idea\n",
    "2. We test the idea\n",
    "3. Based on the results, we refine and improve the idea.\n",
    "\n",
    "Once this iterative process yields noteworthy results, the idea and corresponding test results get distilled into a research paper.\n",
    "\n",
    "Let's say we want to speed up our research. \n",
    "Common sense tells us that we can speed up any process by getting rid of its bottlenecks.\n",
    "The most dominant bottleneck in the procedure above is obviously step number 2. \n",
    "\n",
    "We could run more machine learning experiments if we simply buy a larger quantity of faster compute units.\n",
    "But what if our budget is limited? How can we speed up our research then?\n",
    "\n",
    "The answer is simply waiting.\n",
    "Yes! Moore's law tells us that every 2 years, we get roughly twice the compute performance for the same budget.\n",
    "For instance, here is a plot of how the 32-bit floating-point of Nvidia GPU performance increased in the past decade:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GPU</th>\n",
       "      <th>Year</th>\n",
       "      <th>Gen</th>\n",
       "      <th>Memory</th>\n",
       "      <th>Compute</th>\n",
       "      <th>Tensor cores</th>\n",
       "      <th>Node</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GTX 580</td>\n",
       "      <td>2010-11-01</td>\n",
       "      <td>Fermi</td>\n",
       "      <td>1.5GB</td>\n",
       "      <td>1.581</td>\n",
       "      <td>False</td>\n",
       "      <td>40nm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GTX 680</td>\n",
       "      <td>2012-02-01</td>\n",
       "      <td>Kepler</td>\n",
       "      <td>2GB</td>\n",
       "      <td>3.250</td>\n",
       "      <td>False</td>\n",
       "      <td>28nm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>K40</td>\n",
       "      <td>2013-10-01</td>\n",
       "      <td>Kepler</td>\n",
       "      <td>12GB</td>\n",
       "      <td>5.046</td>\n",
       "      <td>False</td>\n",
       "      <td>28nm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Titan Black</td>\n",
       "      <td>2014-02-01</td>\n",
       "      <td>Kepler</td>\n",
       "      <td>6GB</td>\n",
       "      <td>5.645</td>\n",
       "      <td>False</td>\n",
       "      <td>28nm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K80</td>\n",
       "      <td>2014-11-01</td>\n",
       "      <td>Kepler</td>\n",
       "      <td>2x12GB</td>\n",
       "      <td>8.226</td>\n",
       "      <td>False</td>\n",
       "      <td>28nm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GTX 980 Ti</td>\n",
       "      <td>2015-06-01</td>\n",
       "      <td>Maxwell</td>\n",
       "      <td>6GB</td>\n",
       "      <td>6.060</td>\n",
       "      <td>False</td>\n",
       "      <td>28nm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>M40</td>\n",
       "      <td>2015-11-01</td>\n",
       "      <td>Maxwell</td>\n",
       "      <td>12GB</td>\n",
       "      <td>6.844</td>\n",
       "      <td>False</td>\n",
       "      <td>28nm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GTX 1080</td>\n",
       "      <td>2016-05-01</td>\n",
       "      <td>Pascal</td>\n",
       "      <td>8GB</td>\n",
       "      <td>8.873</td>\n",
       "      <td>False</td>\n",
       "      <td>16nm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>P100</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>Pascal</td>\n",
       "      <td>16GB</td>\n",
       "      <td>10.610</td>\n",
       "      <td>False</td>\n",
       "      <td>16nm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GTX 1080Ti</td>\n",
       "      <td>2017-03-01</td>\n",
       "      <td>Pascal</td>\n",
       "      <td>11GB</td>\n",
       "      <td>11.340</td>\n",
       "      <td>False</td>\n",
       "      <td>16nm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Titan V</td>\n",
       "      <td>2017-12-01</td>\n",
       "      <td>Volta</td>\n",
       "      <td>12GB</td>\n",
       "      <td>14.900</td>\n",
       "      <td>True</td>\n",
       "      <td>12nm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>V100</td>\n",
       "      <td>2018-03-01</td>\n",
       "      <td>Volta</td>\n",
       "      <td>16/32GB</td>\n",
       "      <td>14.130</td>\n",
       "      <td>True</td>\n",
       "      <td>12nm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>T4</td>\n",
       "      <td>2018-09-13</td>\n",
       "      <td>Turing</td>\n",
       "      <td>16GB</td>\n",
       "      <td>8.141</td>\n",
       "      <td>True</td>\n",
       "      <td>12nm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>RTX 2080 Ti</td>\n",
       "      <td>2018-11-01</td>\n",
       "      <td>Turing</td>\n",
       "      <td>12GB</td>\n",
       "      <td>13.450</td>\n",
       "      <td>True</td>\n",
       "      <td>12nm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Titan RTX</td>\n",
       "      <td>2018-12-01</td>\n",
       "      <td>Turing</td>\n",
       "      <td>24GB</td>\n",
       "      <td>16.310</td>\n",
       "      <td>True</td>\n",
       "      <td>12nm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>A100</td>\n",
       "      <td>2020-05-01</td>\n",
       "      <td>Ampere</td>\n",
       "      <td>40GB</td>\n",
       "      <td>19.490</td>\n",
       "      <td>True</td>\n",
       "      <td>7nm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>RTX 3090</td>\n",
       "      <td>2020-09-01</td>\n",
       "      <td>Ampere</td>\n",
       "      <td>24GB</td>\n",
       "      <td>35.700</td>\n",
       "      <td>True</td>\n",
       "      <td>8nm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            GPU       Year      Gen   Memory  Compute  Tensor cores  Node\n",
       "0       GTX 580 2010-11-01    Fermi    1.5GB    1.581         False  40nm\n",
       "1       GTX 680 2012-02-01   Kepler      2GB    3.250         False  28nm\n",
       "2           K40 2013-10-01   Kepler     12GB    5.046         False  28nm\n",
       "3   Titan Black 2014-02-01   Kepler      6GB    5.645         False  28nm\n",
       "4           K80 2014-11-01   Kepler   2x12GB    8.226         False  28nm\n",
       "5    GTX 980 Ti 2015-06-01  Maxwell      6GB    6.060         False  28nm\n",
       "6           M40 2015-11-01  Maxwell     12GB    6.844         False  28nm\n",
       "7      GTX 1080 2016-05-01   Pascal      8GB    8.873         False  16nm\n",
       "8          P100 2016-04-01   Pascal     16GB   10.610         False  16nm\n",
       "9    GTX 1080Ti 2017-03-01   Pascal     11GB   11.340         False  16nm\n",
       "10      Titan V 2017-12-01    Volta     12GB   14.900          True  12nm\n",
       "11         V100 2018-03-01    Volta  16/32GB   14.130          True  12nm\n",
       "12           T4 2018-09-13   Turing     16GB    8.141          True  12nm\n",
       "13  RTX 2080 Ti 2018-11-01   Turing     12GB   13.450          True  12nm\n",
       "14    Titan RTX 2018-12-01   Turing     24GB   16.310          True  12nm\n",
       "15         A100 2020-05-01   Ampere     40GB   19.490          True   7nm\n",
       "16     RTX 3090 2020-09-01   Ampere     24GB   35.700          True   8nm"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "df = pd.DataFrame({'GPU': ['GTX 580'],\n",
    "                   'Year':  [pd.Timestamp(2010,11,1)],\n",
    "        'Gen': ['Fermi'],\n",
    "        'Memory': ['1.5GB'],\n",
    "        'Compute': [1.581],\n",
    "        'Tensor cores': [False],\n",
    "        'Node': ['40nm']\n",
    "        })\n",
    "df = df.append({'Year': pd.Timestamp(2012,2,1), \n",
    "        'GPU': 'GTX 680',\n",
    "        'Gen': 'Kepler',\n",
    "        'Compute': 3.250,\n",
    "        'Memory': '2GB', \n",
    "        'Tensor cores': False,\n",
    "        'Node': '28nm',\n",
    "        },ignore_index=True)\n",
    "df = df.append({'Year': pd.Timestamp(2013,10,1), \n",
    "        'GPU': 'K40',\n",
    "        'Gen': 'Kepler',\n",
    "        'Compute': 5.046,\n",
    "        'Tensor cores': False,\n",
    "        'Memory': '12GB',\n",
    "        'Node': '28nm',\n",
    "        },ignore_index=True)\n",
    "df = df.append({'Year': pd.Timestamp(2014,2,1), \n",
    "        'GPU': 'Titan Black',\n",
    "        'Gen': 'Kepler',\n",
    "        'Tensor cores': False,\n",
    "        'Memory': '6GB',\n",
    "        'Compute': 5.645,\n",
    "        'Node': '28nm',\n",
    "        },ignore_index=True)\n",
    "df = df.append({'Year': pd.Timestamp(2014,11,1), \n",
    "        'GPU': 'K80',\n",
    "        'Gen': 'Kepler',\n",
    "        'Compute': 8.226,\n",
    "        'Tensor cores': False,\n",
    "        'Memory': '2x12GB',\n",
    "        'Node': '28nm',\n",
    "        },ignore_index=True)\n",
    "df = df.append({'Year': pd.Timestamp(2015,6,1), \n",
    "        'GPU': 'GTX 980 Ti',\n",
    "        'Gen': 'Maxwell',\n",
    "        'Compute':6.060 ,\n",
    "        'Tensor cores': False,\n",
    "        'Memory': '6GB',\n",
    "        'Node': '28nm',\n",
    "        },ignore_index=True)\n",
    "\n",
    "\n",
    "df = df.append({'Year': pd.Timestamp(2015,11,1), \n",
    "        'GPU': 'M40',\n",
    "        'Gen': 'Maxwell',\n",
    "        'Compute': 6.844,\n",
    "        'Tensor cores': False,\n",
    "        'Memory': '12GB',\n",
    "        'Node': '28nm',\n",
    "        },ignore_index=True)\n",
    "\n",
    "df = df.append({'Year': pd.Timestamp(2016,5,1), \n",
    "        'GPU': 'GTX 1080',\n",
    "        'Gen': 'Pascal',\n",
    "        'Compute': 8.873,\n",
    "        'Memory': '8GB',\n",
    "        'Tensor cores': False,\n",
    "        'Node': '16nm',\n",
    "        },ignore_index=True)\n",
    "\n",
    "\n",
    "df = df.append({'Year': pd.Timestamp(2016,4,1), \n",
    "        'GPU': 'P100',\n",
    "        'Gen': 'Pascal',\n",
    "        'Compute': 10.61,\n",
    "        'Memory': '16GB',\n",
    "        'Tensor cores': False,\n",
    "        'Node': '16nm',\n",
    "        },ignore_index=True)\n",
    "\n",
    "df = df.append({'Year': pd.Timestamp(2017,3,1), \n",
    "        'GPU': 'GTX 1080Ti',\n",
    "        'Gen': 'Pascal',\n",
    "        'Compute': 11.34,\n",
    "        'Memory': '11GB',\n",
    "        'Tensor cores': False,\n",
    "        'Node': '16nm',\n",
    "        },ignore_index=True)\n",
    "\n",
    "df = df.append({'Year': pd.Timestamp(2017,12,1), \n",
    "        'GPU': 'Titan V',\n",
    "        'Gen': 'Volta',\n",
    "        'Compute': 14.90,\n",
    "        'Memory': '12GB',\n",
    "        'Tensor cores': True,\n",
    "        'Node': '12nm',\n",
    "        },ignore_index=True)\n",
    "df = df.append({'Year': pd.Timestamp(2018,3,1), \n",
    "        'GPU': 'V100',\n",
    "        'Gen': 'Volta',\n",
    "        'Compute': 14.13,\n",
    "        'Memory': '16/32GB',\n",
    "        'Tensor cores': True,\n",
    "        'Node': '12nm',\n",
    "        },ignore_index=True)\n",
    "df = df.append({'Year': pd.Timestamp(2018,9,13), \n",
    "        'GPU': 'T4',\n",
    "        'Gen': 'Turing',\n",
    "        'Compute': 8.141 ,\n",
    "        'Memory': '16GB',\n",
    "        'Tensor cores': True,\n",
    "        'Node': '12nm',\n",
    "        },ignore_index=True)\n",
    "df = df.append({'Year': pd.Timestamp(2018,11,1), \n",
    "        'GPU': 'RTX 2080 Ti',\n",
    "        'Gen': 'Turing',\n",
    "        'Compute': 13.45,\n",
    "        'Memory': '12GB',\n",
    "        'Tensor cores': True,\n",
    "        'Node': '12nm',\n",
    "        },ignore_index=True)\n",
    "df = df.append({'Year': pd.Timestamp(2018,12,1), \n",
    "        'GPU': 'Titan RTX',\n",
    "        'Gen': 'Turing',\n",
    "        'Compute': 16.31,\n",
    "        'Memory': '24GB',\n",
    "        'Tensor cores': True,\n",
    "        'Node': '12nm',\n",
    "        },ignore_index=True)\n",
    "\n",
    "df = df.append({'Year': pd.Timestamp(2020,5,1), \n",
    "        'GPU': 'A100',\n",
    "        'Gen': 'Ampere',\n",
    "        'Compute': 19.49 ,\n",
    "        'Memory': '40GB',\n",
    "        'Tensor cores': True,\n",
    "        'Node': '7nm',\n",
    "        },ignore_index=True)\n",
    "\n",
    "df = df.append({'Year': pd.Timestamp(2020,9,1), \n",
    "        'GPU': 'RTX 3090',\n",
    "        'Gen': 'Ampere',\n",
    "        'Compute': 35.7,\n",
    "        'Memory': '24GB',\n",
    "        'Tensor cores': True,\n",
    "        'Node': '8nm',\n",
    "        },ignore_index=True)\n",
    "\n",
    " \n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-592718543bd643aab4a24d9d3ae74b7e\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-592718543bd643aab4a24d9d3ae74b7e\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-592718543bd643aab4a24d9d3ae74b7e\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.8.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function loadScript(lib) {\n",
       "      return new Promise(function(resolve, reject) {\n",
       "        var s = document.createElement('script');\n",
       "        s.src = paths[lib];\n",
       "        s.async = true;\n",
       "        s.onload = () => resolve(paths[lib]);\n",
       "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "      });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else if (typeof vegaEmbed === \"function\") {\n",
       "      displayChart(vegaEmbed);\n",
       "    } else {\n",
       "      loadScript(\"vega\")\n",
       "        .then(() => loadScript(\"vega-lite\"))\n",
       "        .then(() => loadScript(\"vega-embed\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"layer\": [{\"mark\": {\"type\": \"circle\", \"size\": 60}, \"encoding\": {\"color\": {\"type\": \"nominal\", \"field\": \"Gen\"}, \"tooltip\": [{\"type\": \"quantitative\", \"field\": \"Compute\"}, {\"type\": \"nominal\", \"field\": \"Node\"}, {\"type\": \"nominal\", \"field\": \"Gen\"}, {\"type\": \"nominal\", \"field\": \"Memory\"}, {\"type\": \"nominal\", \"field\": \"Tensor cores\"}], \"x\": {\"type\": \"temporal\", \"field\": \"Year\", \"scale\": {\"domain\": [\"2010-01-01T00:00:00\", \"2021-07-01T00:00:00\"]}}, \"y\": {\"type\": \"quantitative\", \"axis\": {\"title\": \"float32 Teraflop/s\"}, \"field\": \"Compute\"}}, \"height\": 400, \"width\": 600}, {\"mark\": {\"type\": \"text\", \"align\": \"left\", \"baseline\": \"middle\", \"dx\": 7}, \"encoding\": {\"color\": {\"type\": \"nominal\", \"field\": \"Gen\"}, \"text\": {\"type\": \"nominal\", \"field\": \"GPU\"}, \"tooltip\": [{\"type\": \"quantitative\", \"field\": \"Compute\"}, {\"type\": \"nominal\", \"field\": \"Node\"}, {\"type\": \"nominal\", \"field\": \"Gen\"}, {\"type\": \"nominal\", \"field\": \"Memory\"}, {\"type\": \"nominal\", \"field\": \"Tensor cores\"}], \"x\": {\"type\": \"temporal\", \"field\": \"Year\", \"scale\": {\"domain\": [\"2010-01-01T00:00:00\", \"2021-07-01T00:00:00\"]}}, \"y\": {\"type\": \"quantitative\", \"axis\": {\"title\": \"float32 Teraflop/s\"}, \"field\": \"Compute\"}}, \"height\": 400, \"width\": 600}], \"data\": {\"name\": \"data-08279906167b235556d6dbb6c29964f4\"}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.8.1.json\", \"datasets\": {\"data-08279906167b235556d6dbb6c29964f4\": [{\"GPU\": \"GTX 580\", \"Year\": \"2010-11-01T00:00:00\", \"Gen\": \"Fermi\", \"Memory\": \"1.5GB\", \"Compute\": 1.581, \"Tensor cores\": false, \"Node\": \"40nm\"}, {\"GPU\": \"GTX 680\", \"Year\": \"2012-02-01T00:00:00\", \"Gen\": \"Kepler\", \"Memory\": \"2GB\", \"Compute\": 3.25, \"Tensor cores\": false, \"Node\": \"28nm\"}, {\"GPU\": \"K40\", \"Year\": \"2013-10-01T00:00:00\", \"Gen\": \"Kepler\", \"Memory\": \"12GB\", \"Compute\": 5.046, \"Tensor cores\": false, \"Node\": \"28nm\"}, {\"GPU\": \"Titan Black\", \"Year\": \"2014-02-01T00:00:00\", \"Gen\": \"Kepler\", \"Memory\": \"6GB\", \"Compute\": 5.645, \"Tensor cores\": false, \"Node\": \"28nm\"}, {\"GPU\": \"K80\", \"Year\": \"2014-11-01T00:00:00\", \"Gen\": \"Kepler\", \"Memory\": \"2x12GB\", \"Compute\": 8.226, \"Tensor cores\": false, \"Node\": \"28nm\"}, {\"GPU\": \"GTX 980 Ti\", \"Year\": \"2015-06-01T00:00:00\", \"Gen\": \"Maxwell\", \"Memory\": \"6GB\", \"Compute\": 6.06, \"Tensor cores\": false, \"Node\": \"28nm\"}, {\"GPU\": \"M40\", \"Year\": \"2015-11-01T00:00:00\", \"Gen\": \"Maxwell\", \"Memory\": \"12GB\", \"Compute\": 6.844, \"Tensor cores\": false, \"Node\": \"28nm\"}, {\"GPU\": \"GTX 1080\", \"Year\": \"2016-05-01T00:00:00\", \"Gen\": \"Pascal\", \"Memory\": \"8GB\", \"Compute\": 8.873, \"Tensor cores\": false, \"Node\": \"16nm\"}, {\"GPU\": \"P100\", \"Year\": \"2016-04-01T00:00:00\", \"Gen\": \"Pascal\", \"Memory\": \"16GB\", \"Compute\": 10.61, \"Tensor cores\": false, \"Node\": \"16nm\"}, {\"GPU\": \"GTX 1080Ti\", \"Year\": \"2017-03-01T00:00:00\", \"Gen\": \"Pascal\", \"Memory\": \"11GB\", \"Compute\": 11.34, \"Tensor cores\": false, \"Node\": \"16nm\"}, {\"GPU\": \"Titan V\", \"Year\": \"2017-12-01T00:00:00\", \"Gen\": \"Volta\", \"Memory\": \"12GB\", \"Compute\": 14.9, \"Tensor cores\": true, \"Node\": \"12nm\"}, {\"GPU\": \"V100\", \"Year\": \"2018-03-01T00:00:00\", \"Gen\": \"Volta\", \"Memory\": \"16/32GB\", \"Compute\": 14.13, \"Tensor cores\": true, \"Node\": \"12nm\"}, {\"GPU\": \"T4\", \"Year\": \"2018-09-13T00:00:00\", \"Gen\": \"Turing\", \"Memory\": \"16GB\", \"Compute\": 8.141, \"Tensor cores\": true, \"Node\": \"12nm\"}, {\"GPU\": \"RTX 2080 Ti\", \"Year\": \"2018-11-01T00:00:00\", \"Gen\": \"Turing\", \"Memory\": \"12GB\", \"Compute\": 13.45, \"Tensor cores\": true, \"Node\": \"12nm\"}, {\"GPU\": \"Titan RTX\", \"Year\": \"2018-12-01T00:00:00\", \"Gen\": \"Turing\", \"Memory\": \"24GB\", \"Compute\": 16.31, \"Tensor cores\": true, \"Node\": \"12nm\"}, {\"GPU\": \"A100\", \"Year\": \"2020-05-01T00:00:00\", \"Gen\": \"Ampere\", \"Memory\": \"40GB\", \"Compute\": 19.49, \"Tensor cores\": true, \"Node\": \"7nm\"}, {\"GPU\": \"RTX 3090\", \"Year\": \"2020-09-01T00:00:00\", \"Gen\": \"Ampere\", \"Memory\": \"24GB\", \"Compute\": 35.7, \"Tensor cores\": true, \"Node\": \"8nm\"}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide_input\n",
    "points = alt.Chart(df).mark_circle(size=60).encode(\n",
    "    alt.X('Year:T',scale=alt.Scale(domain=(pd.Timestamp(2010,1,1), pd.Timestamp(2021,7,1)))),\n",
    "    y=alt.Y('Compute',axis=alt.Axis(title=\"float32 Teraflop/s\")),\n",
    "    color='Gen',\n",
    "    tooltip=['Compute', 'Node','Gen','Memory','Tensor cores']\n",
    ").properties(\n",
    "    width=600,\n",
    "    height=400\n",
    ")\n",
    "\n",
    "text = points.mark_text(\n",
    "    align='left',\n",
    "    baseline='middle',\n",
    "    dx=7\n",
    ").encode(\n",
    "    text='GPU'\n",
    ")\n",
    "points + text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that in terms of float32 performance, the RTX 3090 released in September of 2020 offers around 23x the float32 throughput of the GTX 580 release 9 years and 10 months prior.\n",
    "\n",
    "Interestingly, this chart does not even include the improvements of [mixed-precision methods](https://docs.nvidia.com/deeplearning/performance/mixed-precision-training/index.html) and other tricks that achieve higher performance by sacrificing numerical precision. For instance, Nvidia's latest A100 can perform 156 Teraflop/s when using for machine learning dedicated TensorCores together with the slightly less precise [TensorFloat32](https://devblogs.nvidia.com/nvidia-ampere-architecture-in-depth/) numerical format.\n",
    "If we compare the TensorFloat32 throughput of the A100 to the GTX 580 used by Alex Krizhevsky to train [AlexNet](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf), we see a 100x scaling in compute performance in almost exactly ten years. \n",
    "\n",
    "\n",
    "## But what about larger models and datasets?\n",
    "\n",
    "Of course, the statement about the doubling of the architecture tuning assumes that the datasets and extend of the networks does not change dramatically.\n",
    "However, given that ImageNet is still the de-facto standard computer vision benchmark (special credit to Prof. Fei-Fei), and the fact that the top-performing networks in 2019/2020 ([EfficientNet](https://arxiv.org/pdf/1905.11946.pdf)) are smaller than their 2015/2016 counterparts ([ResNet](https://arxiv.org/pdf/1512.03385.pdf)/[ResNeXt](https://arxiv.org/pdf/1611.05431.pdf)), this assumption seems to hold for now.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "Moore's law continues to make compute resources faster and cheaper. This increase in compute performance allows machine learning researchers to test a larger variety of new architecture and training methods. Therefore, I am expecting that research will continue to yield better neural archtectiures and training algorithms.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
